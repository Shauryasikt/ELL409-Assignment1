{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ascores: [0.8928571428571429, 0.8071428571428572, 0.8714285714285714, 0.8571428571428571, 0.85]\n",
      "Pscores: [0.9285714285714286, 0.7547169811320755, 0.7719298245614035, 0.8253968253968254, 0.8448275862068966]\n",
      "Rscores: [0.8666666666666667, 0.7407407407407407, 0.8979591836734694, 0.8524590163934426, 0.8032786885245902]\n",
      "F1scores: [0.896551724137931, 0.7476635514018692, 0.8301886792452831, 0.8387096774193549, 0.823529411764706]\n",
      "Sscores: [0.9230769230769231, 0.8488372093023255, 0.8571428571428571, 0.8607594936708861, 0.8860759493670886]\n",
      "Mean Accuracy: 0.8557142857142856\n",
      "Mean Precision: 0.8250885291737259\n",
      "Mean Recall: 0.832220859199782\n",
      "Mean F1 score: 0.8273286087938289\n",
      "Mean specificity: 0.8751784865120161\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from csv import reader\n",
    "from random import seed\n",
    "from random import randrange\n",
    "import PriorUtils as pu\n",
    "import CorrectnessMetricUtils as cmu\n",
    "import ErrorMetricsUtils as emu\n",
    "\n",
    "# Get CSV file\n",
    "def get_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        data = reader(file)\n",
    "        for row in data:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "# String to float columnwise\n",
    "def str_to_float_col(dataset, col):\n",
    "    for row in dataset:\n",
    "        row[col] = float(row[col].strip())\n",
    "        \n",
    "# Split dataset into n folds\n",
    "def crossval_split(dataset, n_folds):\n",
    "    split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_dim = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_dim:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        split.append(fold)\n",
    "    return split\n",
    "\n",
    "# Divide dataset by class\n",
    "def class_divider(dataset):\n",
    "    divided = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        row = dataset[i]\n",
    "        class_type = row[-1]\n",
    "        if (class_type not in divided):\n",
    "            divided[class_type] = list()\n",
    "        divided[class_type].append(row)\n",
    "    return divided\n",
    "\n",
    "# Mean, stde and count columnwise\n",
    "def dataset_info(dataset):\n",
    "    info = [(np.mean(col), np.std(col), len(col)) for col in zip(*dataset)]\n",
    "    del(info[-1]) #not reqd for class labels\n",
    "    return info\n",
    "\n",
    "# Classwise column stats\n",
    "def class_info(dataset):\n",
    "    divided = class_divider(dataset)\n",
    "    info = dict()\n",
    "    for class_type, rows in divided.items():\n",
    "        info[class_type] = dataset_info(rows)\n",
    "    return info\n",
    "\n",
    "# Calculate probabilities of predicting each class for given row\n",
    "def calc_class_probs(info, row):\n",
    "    total_rows = sum([info[label][0][2] for label in info])\n",
    "    probs = dict()\n",
    "    for class_type, class_info in info.items():\n",
    "        probs[class_type] = info[class_type][0][2]/float(total_rows)\n",
    "        for i in range(len(class_info)):\n",
    "            mean, std, _ = class_info[i]\n",
    "            probs[class_type] *= pu.Gaussian(row[i], mean, std)\n",
    "    return probs\n",
    "\n",
    "# Predict class type for given row\n",
    "def predict(info, row):\n",
    "    probs = calc_class_probs(info, row)\n",
    "    best_label, best_prob = None, -1\n",
    "    for class_type, prob in probs.items():\n",
    "        if best_label is None or prob > best_prob:\n",
    "            best_prob = prob\n",
    "            best_label = class_type\n",
    "    return best_label\n",
    "\n",
    "# Algo evaluation by cross validation split\n",
    "def eval_algo(dataset, algo, n_folds, obs_label, *args):\n",
    "    folds = crossval_split(dataset, n_folds)\n",
    "    Ascores = list()\n",
    "    Pscores = list()\n",
    "    Rscores = list()\n",
    "    Fscores = list()\n",
    "    Sscores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algo(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = cmu.accuracy_calc(actual, predicted)\n",
    "        precision = cmu.precision_calc(obs_label, actual, predicted)\n",
    "        recall = cmu.recall_calc(obs_label, actual, predicted)\n",
    "        f1 = cmu.f1_calc(obs_label, actual, predicted)\n",
    "        spec = cmu.specificity_calc(obs_label, actual, predicted)\n",
    "        Ascores.append(accuracy)\n",
    "        Pscores.append(precision)\n",
    "        Rscores.append(recall)\n",
    "        Fscores.append(f1)\n",
    "        Sscores.append(spec)\n",
    "    return Ascores, Pscores, Rscores, Fscores, Sscores\n",
    "\n",
    "# Naive Bayes Algorithm\n",
    "def naive_bayes(train, test):\n",
    "    info = class_info(train)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        output = predict(info, row)\n",
    "        predictions.append(output)\n",
    "    return(predictions)\n",
    "\n",
    "# Test Naive Bayes\n",
    "seed(1)\n",
    "filename = 'bc.csv'\n",
    "dataset = get_csv(filename)\n",
    "dataset.remove(dataset[0])\n",
    "for i in range(len(dataset[0])):\n",
    "    str_to_float_col(dataset, i)\n",
    "\n",
    "# class clo values as int or float?\n",
    "    \n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "Ascores, Pscores, Rscores, Fscores, Sscores = eval_algo(dataset, naive_bayes, n_folds, 1)\n",
    "print('Ascores: %s' % Ascores)\n",
    "print('Pscores: %s' % Pscores)\n",
    "print('Rscores: %s' % Rscores)\n",
    "print('F1scores: %s' % Fscores)\n",
    "print('Sscores: %s' % Sscores)\n",
    "print('Mean Accuracy: %s' % (sum(Ascores)/float(len(Ascores))))\n",
    "print('Mean Precision: %s' % (sum(Pscores)/float(len(Pscores))))\n",
    "print('Mean Recall: %s' % (sum(Rscores)/float(len(Rscores))))\n",
    "print('Mean F1 score: %s' % (sum(Fscores)/float(len(Fscores))))\n",
    "print('Mean specificity: %s' % (sum(Sscores)/float(len(Sscores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
