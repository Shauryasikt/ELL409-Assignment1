{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore various classifier algorithms on the dataset from https://www.dropbox.com/s/z9ebwa49koaqs7i/Medical_MNIST.zip?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due to the dataset being extremely tedious, we refrained from using weaker algorithms like Linear Discriminant Analysis. Moreover, due to this being a non-binary classification we skipped the generalized linear models like Logistic Regression and Perceptron as well**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Owing to the size of the initial dataset that was over 200MB, GitHub did not allow the uploading of such a huge file. For the code that follows we took the dataset after having separate;y downloaded it into our working folder on the local device.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import math\n",
    "import os, sys, itertools\n",
    "from csv import reader\n",
    "from random import seed\n",
    "from random import randrange\n",
    "import AuxUtils as au\n",
    "import PriorUtils as pu\n",
    "import CorrectnessMetricUtils as cmu\n",
    "import ErrorMetricsUtils as emu\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Preparation:** We will approaxh this issue by the following steps: **(1)** Reading and resizing the image **(2)** Reading the image into a numpy array **(3)** Appending its class type as numbers with index starting from 0 to the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preparing dataset\n",
    "path = 'Medical_MNIST'\n",
    "dataset = list()\n",
    "\n",
    "i = 0\n",
    "for item in os.listdir(path):\n",
    "    subpath = path + \"\\\\\" + item\n",
    "    for subitem in os.listdir(subpath):\n",
    "        imgpath = subpath + \"\\\\\" + subitem\n",
    "        img = Image.open(imgpath)                  #reading image\n",
    "        img = img.resize((32,32))                  #resizing to 32x32\n",
    "        np_img = np.asarray(img)                   #converting to np array\n",
    "        np_img = np_img.flatten()                  #converting to 1D array\n",
    "        np_img = list(np_img)\n",
    "        np_img.append(i)                           #adding class type as last element in the list\n",
    "        dataset.append(np_img)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>99</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58949</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>96</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58950</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>100</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58951</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>101</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58952</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>95</td>\n",
       "      <td>41</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58953</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>99</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58954 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  1015  \\\n",
       "0       101   101   101   101   101   101   101   101   101   101  ...   102   \n",
       "1       101   101   101   101   101   101   101   101   101   101  ...   101   \n",
       "2       101   101   101   101   101   101   101   101   101   101  ...   102   \n",
       "3       101   101   101   101   101   101   101   101   101   101  ...   102   \n",
       "4       101   101   101   101   101   101   101   101   101   101  ...   102   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "58949    25    25    25    25    25    25    25    25    25    25  ...    25   \n",
       "58950    25    25    25    25    25    25    25    25    25    25  ...    25   \n",
       "58951    25    25    25    25    25    25    25    25    25    25  ...    24   \n",
       "58952    25    25    25    25    25    25    25    25    25    25  ...    26   \n",
       "58953    25    25    25    25    25    25    25    25    25    25  ...    26   \n",
       "\n",
       "       1016  1017  1018  1019  1020  1021  1022  1023  1024  \n",
       "0       101   102   101    99   101   101   101   101     0  \n",
       "1       101   101   102   100   101   101   101   101     0  \n",
       "2       101   101   101   100   101   101   101   101     0  \n",
       "3       100   101   101   101   101   101   101   101     0  \n",
       "4       101   101   101   100   101   101   101   101     0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "58949    24    22    96    44    23    25    27    27     5  \n",
       "58950    23    23   100    38    23    24    25    27     5  \n",
       "58951    25    32   101    31    23    26    27    24     5  \n",
       "58952    23    24    95    41    23    24    24    25     5  \n",
       "58953    24    28    99    35    23    24    25    26     5  \n",
       "\n",
       "[58954 rows x 1025 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizing dataset\n",
    "df = pd.DataFrame(dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the featureset has 1024 feature columns and we have 1 target column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have Gaussian prior probability distribution for sampling the data from the featureset of the first 3 columns. The Naive Bayes Classifier works with MAP estimation serving as it basis. We _assume_ that all the features are **independent** from one another. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 **MLE** for Naive Bayes Classifier, _without_ considering the relative class frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Class Type 0\n",
      "Train Accuracy: 0.8571428571428571\n",
      "Test Accuracy: 0.8571428571428571\n",
      "Mean Precision: 0.8311456607620746\n",
      "Mean Recall: 0.834114774114774\n",
      "Mean F1: 0.8308888576676352\n",
      "Mean Specificity: 0.8766988914975185\n",
      "For Class Type 1\n",
      "Train Accuracy: 0.8571428571428571\n",
      "Test Accuracy: 0.8571428571428571\n",
      "Mean Precision: 0.8327907110956818\n",
      "Mean Recall: 0.8319971139551594\n",
      "Mean F1: 0.831905126234998\n",
      "Mean Specificity: 0.8730873678354698\n",
      "For Class Type 2\n",
      "Train Accuracy: 0.8585714285714285\n",
      "Test Accuracy: 0.8514285714285714\n",
      "Mean Precision: 0.8284048365330199\n",
      "Mean Recall: 0.8278262130815512\n",
      "Mean F1: 0.8271113489481763\n",
      "Mean Specificity: 0.8693468676009051\n",
      "For Class Type 3\n",
      "Train Accuracy: 0.8574999999999999\n",
      "Test Accuracy: 0.8557142857142856\n",
      "Mean Precision: 0.8298896221338279\n",
      "Mean Recall: 0.8318066209829584\n",
      "Mean F1: 0.8297940576736078\n",
      "Mean Specificity: 0.874209814144792\n",
      "For Class Type 4\n",
      "Train Accuracy: 0.8582142857142857\n",
      "Test Accuracy: 0.8528571428571429\n",
      "Mean Precision: 0.8316970997812134\n",
      "Mean Recall: 0.8272927454595974\n",
      "Mean F1: 0.8281484000760597\n",
      "Mean Specificity: 0.8722851577524933\n",
      "For Class Type 5\n",
      "Train Accuracy: 0.8582142857142857\n",
      "Test Accuracy: 0.8528571428571429\n",
      "Mean Precision: 0.8284639767955364\n",
      "Mean Recall: 0.8260608549757069\n",
      "Mean F1: 0.8263269143595876\n",
      "Mean Specificity: 0.873299313829919\n",
      "Macro F1-score: 0.8301240950589683\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into n folds\n",
    "def crossval_split(dataset, n_folds):\n",
    "    split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_dim = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_dim:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        split.append(fold)\n",
    "    return split\n",
    "\n",
    "# Divide dataset by class\n",
    "def class_divider(dataset):\n",
    "    divided = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        row = dataset[i]\n",
    "        class_type = row[-1]\n",
    "        if (class_type not in divided):\n",
    "            divided[class_type] = list()\n",
    "        divided[class_type].append(row)\n",
    "    return divided\n",
    "\n",
    "# Mean, std and count columnwise\n",
    "def dataset_info(dataset):\n",
    "    info = [(np.mean(col), np.std(col), len(col)) for col in zip(*dataset)]\n",
    "    del(info[-1]) #not reqd for class labels\n",
    "    return info\n",
    "\n",
    "# Classwise column stats\n",
    "def class_info(dataset):\n",
    "    divided = class_divider(dataset)\n",
    "    info = dict()\n",
    "    for class_type, rows in divided.items():\n",
    "        info[class_type] = dataset_info(rows)\n",
    "    return info\n",
    "\n",
    "# Calculate probabilities of predicting each class for given row\n",
    "def calc_class_probs_nbmle(info, row, prior):\n",
    "    total_rows = sum([info[label][0][2] for label in info])\n",
    "    probs = dict()\n",
    "    for class_type, class_info in info.items():\n",
    "        probs[class_type] = info[class_type][0][2]/float(total_rows)\n",
    "        for i in range(len(class_info)):\n",
    "            mean, std, _ = class_info[i]\n",
    "            probs[class_type] *= prior(row[i], mean, std)\n",
    "    aux = 0\n",
    "    for class_type, class_info in info.items():\n",
    "        aux += probs[class_type]\n",
    "    for class_type, class_info in info.items():\n",
    "        probs[class_type] = probs[class_type]/aux\n",
    "    return probs\n",
    "\n",
    "# Predict class type for given row\n",
    "def predict_nbmle(info, row, prior):\n",
    "    probs = calc_class_probs_nbmle(info, row, prior)\n",
    "    best_label, best_prob = None, -1\n",
    "    for class_type, prob in probs.items():\n",
    "        if best_label is None or prob > best_prob:\n",
    "            best_prob = prob\n",
    "            best_label = class_type\n",
    "    return best_label\n",
    "\n",
    "# Algo evaluation by cross validation split\n",
    "def eval_algo(dataset, algo, n_folds, obs_label, *args):\n",
    "    folds = crossval_split(dataset, n_folds)\n",
    "    TestScores = list()\n",
    "    TrainScores = list()\n",
    "    Pscores = list()\n",
    "    Rscores = list()\n",
    "    Fscores = list()\n",
    "    Sscores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        test_pred = algo(train_set, test_set, *args)\n",
    "        train_pred = algo(train_set, train_set, *args)\n",
    "        test_actual = [row[-1] for row in fold]\n",
    "        train_actual = [row[-1] for row in train_set]\n",
    "        test_accuracy = cmu.accuracy_calc(test_actual, test_pred)\n",
    "        train_accuracy = cmu.accuracy_calc(train_actual, train_pred)\n",
    "        precision = cmu.precision_calc(obs_label, test_actual, test_pred)\n",
    "        recall = cmu.recall_calc(obs_label, test_actual, test_pred)\n",
    "        f1 = cmu.f1_calc(obs_label, test_actual, test_pred)\n",
    "        spec = cmu.specificity_calc(obs_label, test_actual, test_pred)\n",
    "        TestScores.append(test_accuracy)\n",
    "        TrainScores.append(train_accuracy)\n",
    "        Pscores.append(precision)\n",
    "        Rscores.append(recall)\n",
    "        Fscores.append(f1)\n",
    "        Sscores.append(spec)\n",
    "    return np.mean(TestScores), np.mean(TrainScores), np.mean(Pscores), np.mean(Rscores), np.mean(Fscores), np.mean(Sscores)\n",
    "\n",
    "# Naive Bayes Algorithm simple gaussian\n",
    "def naive_bayes_Gaussian_mle(train, test):\n",
    "    info = class_info(train)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        output = predict_nbmle(info, row, pu.Gaussian)\n",
    "        predictions.append(output)\n",
    "    return(predictions)\n",
    "\n",
    "# evaluate naive bayes (gaussian) algorithm\n",
    "n_folds = 5\n",
    "TrainAcc = list()\n",
    "TestAcc = list()\n",
    "Prec = list()\n",
    "Recall = list()\n",
    "Spec = list()\n",
    "for i in range(6):\n",
    "    TestScores, TrainScores, Pscores, Rscores, Fscores, Sscores = eval_algo(dataset, naive_bayes_Gaussian_mle, n_folds, i)\n",
    "    print(\"For Class Type\", i)\n",
    "    print('Train Accuracy: %s' % TrainScores)\n",
    "    print('Test Accuracy: %s' % TestScores)\n",
    "    print('Mean Precision: %s' % Pscores)\n",
    "    print('Mean Recall: %s' % Rscores)\n",
    "    print('Mean F1: %s' % Fscores)\n",
    "    print('Mean Specificity: %s' % Sscores)\n",
    "    TrainAcc.append(TrainScores)\n",
    "    TestAcc.append(TestScores)\n",
    "    Prec.append(Pscores)\n",
    "    Recall.append(Rscores)\n",
    "    Spec.append(Sscores)\n",
    "    \n",
    "Macro_prec = np.mean(Prec)\n",
    "Macro_recall = np.mean(Recall)\n",
    "Macro_F1 = 2*Macro_prec*Macro_recall/(Macro_prec + Macro_recall)\n",
    "print('Macro F1-score: %s' % Macro_F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Naive Bayes Classifier with **MAP**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Class Type 0\n",
      "Train Accuracy: 0.8567857142857143\n",
      "Test Accuracy: 0.8585714285714285\n",
      "Mean Precision: 0.8455963225768766\n",
      "Mean Recall: 0.8197324574850476\n",
      "Mean F1: 0.8298173923921768\n",
      "Mean Specificity: 0.8878279905649226\n",
      "For Class Type 1\n",
      "Train Accuracy: 0.8582142857142857\n",
      "Test Accuracy: 0.8528571428571429\n",
      "Mean Precision: 0.8332396204332854\n",
      "Mean Recall: 0.820987871698201\n",
      "Mean F1: 0.8261208873333921\n",
      "Mean Specificity: 0.8788205360115361\n",
      "For Class Type 2\n",
      "Train Accuracy: 0.8578571428571429\n",
      "Test Accuracy: 0.8542857142857143\n",
      "Mean Precision: 0.8379753136245922\n",
      "Mean Recall: 0.8174671412569146\n",
      "Mean F1: 0.8260512127304768\n",
      "Mean Specificity: 0.8832505190173082\n",
      "For Class Type 3\n",
      "Train Accuracy: 0.8564285714285713\n",
      "Test Accuracy: 0.86\n",
      "Mean Precision: 0.8456294214668981\n",
      "Mean Recall: 0.8281205399768832\n",
      "Mean F1: 0.8350420633426223\n",
      "Mean Specificity: 0.885447784636901\n",
      "For Class Type 4\n",
      "Train Accuracy: 0.8571428571428573\n",
      "Test Accuracy: 0.8571428571428571\n",
      "Mean Precision: 0.8445664048707376\n",
      "Mean Recall: 0.81657867729669\n",
      "Mean F1: 0.8300340841189536\n",
      "Mean Specificity: 0.8869678398169978\n",
      "For Class Type 5\n",
      "Train Accuracy: 0.8575000000000002\n",
      "Test Accuracy: 0.8557142857142856\n",
      "Mean Precision: 0.8396780303030305\n",
      "Mean Recall: 0.8142436068610159\n",
      "Mean F1: 0.8263507700940534\n",
      "Mean Specificity: 0.88651499014005\n",
      "Macro F1-score: 0.8301775722753378\n"
     ]
    }
   ],
   "source": [
    "# relative class frequencies in the dataset\n",
    "data = np.asarray(dataset)\n",
    "target = data.T[1024]\n",
    "x = class_info(dataset)\n",
    "class_types = list()\n",
    "total = 0\n",
    "for i in range(len(x)):\n",
    "    class_types.append(i)\n",
    "    class_types[i] = list()\n",
    "    class_types[i].append(x[i][0][-1])\n",
    "    total += class_types[i][0]\n",
    "class_probs = list()\n",
    "for i in range(len(x)):\n",
    "    class_probs.append(class_types[i][0]/float(total))\n",
    "\n",
    "# Calculate probabilities of predicting each class for given row\n",
    "def calc_class_probs_nbmap(info, row, prior):\n",
    "    total_rows = sum([info[label][0][2] for label in info])\n",
    "    probs = dict()\n",
    "    for class_type, class_info in info.items():\n",
    "        probs[class_type] = info[class_type][0][2]/float(total_rows)\n",
    "        for i in range(len(class_info)):\n",
    "            mean, std, _ = class_info[i]\n",
    "            probs[class_type] *= prior(row[i], mean, std)\n",
    "    aux = 0\n",
    "    for class_type, class_info in info.items():\n",
    "        aux += probs[class_type]\n",
    "    for class_type, class_info in info.items():\n",
    "        probs[class_type] = probs[class_type]/aux\n",
    "    return probs\n",
    "\n",
    "# Calculate probabilities of predicting each class for given row\n",
    "def calc_class_probs_nbmap(info, row, prior):\n",
    "    total_rows = sum([info[label][0][2] for label in info])\n",
    "    probs = dict()\n",
    "    for class_type, class_info in info.items():\n",
    "        probs[class_type] = info[class_type][0][2]/float(total_rows)\n",
    "        for i in range(len(class_info)):\n",
    "            mean, std, _ = class_info[i]\n",
    "            probs[class_type] *= prior(row[i], mean, std)\n",
    "        if class_type == 0.0:                                                      #incorporating relative class frequencies\n",
    "            probs[class_type] *= class_probs[0] \n",
    "        elif class_type == 1.0:\n",
    "            probs[class_type] *= class_probs[1]\n",
    "        elif class_type == 2.0:\n",
    "            probs[class_type] *= class_probs[2]\n",
    "        elif class_type == 3.0:\n",
    "            probs[class_type] *= class_probs[3]\n",
    "        elif class_type == 4.0:\n",
    "            probs[class_type] *= class_probs[4]\n",
    "        elif class_type == 5.0:\n",
    "            probs[class_type] *= class_probs[5]\n",
    "    aux = 0\n",
    "    for class_type, class_info in info.items():\n",
    "        aux += probs[class_type]\n",
    "    for class_type, class_info in info.items():\n",
    "        probs[class_type] = probs[class_type]/aux\n",
    "    return probs\n",
    "\n",
    "# Naive Bayes Algorithm simple gaussian\n",
    "def naive_bayes_Gaussian_map(train, test):\n",
    "    info = class_info(train)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        output = predict_nbmap(info, row, pu.Gaussian)\n",
    "        predictions.append(output)\n",
    "    return(predictions)\n",
    "\n",
    "# evaluate naive bayes (gaussian) algorithm\n",
    "n_folds = 5\n",
    "TrainAcc = list()\n",
    "TestAcc = list()\n",
    "Prec = list()\n",
    "Recall = list()\n",
    "Spec = list()\n",
    "for i in range(6):\n",
    "    TestScores, TrainScores, Pscores, Rscores, Fscores, Sscores = eval_algo(dataset, naive_bayes_Gaussian_map, n_folds, i)\n",
    "    print(\"For Class Type\", i)\n",
    "    print('Train Accuracy: %s' % TrainScores)\n",
    "    print('Test Accuracy: %s' % TestScores)\n",
    "    print('Mean Precision: %s' % Pscores)\n",
    "    print('Mean Recall: %s' % Rscores)\n",
    "    print('Mean F1: %s' % Fscores)\n",
    "    print('Mean Specificity: %s' % Sscores)\n",
    "    TrainAcc.append(TrainScores)\n",
    "    TestAcc.append(TestScores)\n",
    "    Prec.append(Pscores)\n",
    "    Recall.append(Rscores)\n",
    "    Spec.append(Sscores)\n",
    "    \n",
    "Macro_prec = np.mean(Prec)\n",
    "Macro_recall = np.mean(Recall)\n",
    "Macro_F1 = 2*Macro_prec*Macro_recall/(Macro_prec + Macro_recall)\n",
    "print('Macro F1-score: %s' % Macro_F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayes Classifier works with MLE estimation serving as it basis. We assume that all the features have some dependency on one another as shown in the usage of covariance matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 WIth Gaussian Distribution as Class Conditional Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Class Type 0\n",
      "Train Accuracy: 0.8596428571428572\n",
      "Test Accuracy: 0.8471428571428572\n",
      "Mean Precision: 0.8018489918489917\n",
      "Mean Recall: 0.858154055457708\n",
      "Mean F1: 0.8256951895602309\n",
      "Mean Specificity: 0.8409347019866995\n",
      "For Class Type 1\n",
      "Train Accuracy: 0.8564285714285713\n",
      "Test Accuracy: 0.86\n",
      "Mean Precision: 0.8143965883691913\n",
      "Mean Recall: 0.8614184782608696\n",
      "Mean F1: 0.8367149881748421\n",
      "Mean Specificity: 0.8543773940205405\n",
      "For Class Type 2\n",
      "Train Accuracy: 0.8582142857142857\n",
      "Test Accuracy: 0.8528571428571429\n",
      "Mean Precision: 0.8166757853518417\n",
      "Mean Recall: 0.8425637429424245\n",
      "Mean F1: 0.8287511213826647\n",
      "Mean Specificity: 0.8563049557457179\n",
      "For Class Type 3\n",
      "Train Accuracy: 0.8589285714285715\n",
      "Test Accuracy: 0.85\n",
      "Mean Precision: 0.8064716234278674\n",
      "Mean Recall: 0.8528923825626311\n",
      "Mean F1: 0.8278641194693274\n",
      "Mean Specificity: 0.848188606461133\n",
      "For Class Type 4\n",
      "Train Accuracy: 0.8578571428571428\n",
      "Test Accuracy: 0.8542857142857143\n",
      "Mean Precision: 0.8060627045348292\n",
      "Mean Recall: 0.8712171961748233\n",
      "Mean F1: 0.8367207151124904\n",
      "Mean Specificity: 0.8426888125443337\n",
      "For Class Type 5\n",
      "Train Accuracy: 0.8585714285714288\n",
      "Test Accuracy: 0.8514285714285714\n",
      "Mean Precision: 0.8096350692577401\n",
      "Mean Recall: 0.8516161616161616\n",
      "Mean F1: 0.8299001277140656\n",
      "Mean Specificity: 0.8495019924431689\n",
      "Macro F1-score: 0.8320792652234872\n"
     ]
    }
   ],
   "source": [
    "# Mean rv, cov_mat and count\n",
    "def dataset_info(dataset):\n",
    "    info_aux = [(np.mean(col), np.std(col), len(col)) for col in zip(*dataset)]\n",
    "    del(info_aux[-1]) #not reqd for class labels\n",
    "    ovr_mean_rv = list()\n",
    "    size = info_aux[0][-1]\n",
    "    cov_mat = np.zeros((len(info_aux), len(info_aux)))\n",
    "    for i in range(len(info_aux)):\n",
    "        ovr_mean_rv.append(info_aux[i][0])\n",
    "    np_ds = np.asarray(dataset)\n",
    "    np_ds = np_ds[:, :-1]\n",
    "    np_ovr_mean = np.asarray(ovr_mean_rv)\n",
    "    for i in range(len(np_ds)):\n",
    "        xn = np.array([np_ds[i]])\n",
    "        cov_mat += np.matmul((xn - np_ovr_mean).T,(xn - np_ovr_mean))\n",
    "    cov_mat = cov_mat/float(size) \n",
    "    info = list()\n",
    "    info.append(ovr_mean_rv)\n",
    "    info.append(cov_mat)\n",
    "    info.append(size)\n",
    "    return info\n",
    "\n",
    "# Calculate probabilities of predicting each class for given row\n",
    "def calc_class_probs_bayes_g(info, row):\n",
    "    probs = dict()\n",
    "    for class_type, class_info in info.items():\n",
    "        mean_rv = np.array(class_info[0])\n",
    "        cov_matrix = class_info[1]\n",
    "        probs[class_type] = pu.multi_normal(np.asarray(row)[:-1], mean_rv, cov_matrix)\n",
    "    aux = 0\n",
    "    for class_type, class_info in info.items():\n",
    "        aux += probs[class_type]\n",
    "    for class_type, class_info in info.items():\n",
    "        probs[class_type] = probs[class_type]/aux\n",
    "    return probs\n",
    "\n",
    "# Predict class type for given row\n",
    "def predict_bayes_g(info, row):\n",
    "    probs = calc_class_probs_bayes_g(info, row)\n",
    "    best_label, best_prob = None, -1\n",
    "    for class_type, prob in probs.items():\n",
    "        if best_label is None or prob > best_prob:\n",
    "            best_prob = prob\n",
    "            best_label = class_type\n",
    "    return best_label\n",
    "\n",
    "# Bayes Algorithm simple gaussian\n",
    "def bayes_Gaussian(train, test):\n",
    "    info = class_info(train)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        output = predict_bayes_g(info, row)\n",
    "        predictions.append(output)\n",
    "    return(predictions)\n",
    "\n",
    "# evaluate bayes (gaussian) algorithm\n",
    "n_folds = 5\n",
    "TrainAcc = list()\n",
    "TestAcc = list()\n",
    "Prec = list()\n",
    "Recall = list()\n",
    "Spec = list()\n",
    "for i in range(6):\n",
    "    TestScores, TrainScores, Pscores, Rscores, Fscores, Sscores = eval_algo(dataset, bayes_Gaussian, n_folds, 1, 0.5)\n",
    "    print(\"For Class Type\", i)\n",
    "    print('Train Accuracy: %s' % TrainScores)\n",
    "    print('Test Accuracy: %s' % TestScores)\n",
    "    print('Mean Precision: %s' % Pscores)\n",
    "    print('Mean Recall: %s' % Rscores)\n",
    "    print('Mean F1: %s' % Fscores)\n",
    "    print('Mean Specificity: %s' % Sscores)\n",
    "    TrainAcc.append(TrainScores)\n",
    "    TestAcc.append(TestScores)\n",
    "    Prec.append(Pscores)\n",
    "    Recall.append(Rscores)\n",
    "    Spec.append(Sscores)\n",
    "    \n",
    "Macro_prec = np.mean(Prec)\n",
    "Macro_recall = np.mean(Recall)\n",
    "Macro_F1 = 2*Macro_prec*Macro_recall/(Macro_prec + Macro_recall)\n",
    "print('Macro F1-score: %s' % Macro_F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 WIth Gaussian Mixture Models as Class Conditional Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Class Type 0\n",
      "Train Accuracy: 0.8578571428571429\n",
      "Test Accuracy: 0.8542857142857143\n",
      "Mean Precision: 0.8099119955902758\n",
      "Mean Recall: 0.8589668396120009\n",
      "Mean F1: 0.8329288328571506\n",
      "Mean Specificity: 0.8504243054243055\n",
      "For Class Type 1\n",
      "Train Accuracy: 0.8589285714285715\n",
      "Test Accuracy: 0.85\n",
      "Mean Precision: 0.8001486518636478\n",
      "Mean Recall: 0.8614379442318206\n",
      "Mean F1: 0.8293056505478047\n",
      "Mean Specificity: 0.8397677631010965\n",
      "For Class Type 2\n",
      "Train Accuracy: 0.8589285714285714\n",
      "Test Accuracy: 0.85\n",
      "Mean Precision: 0.8042958870579838\n",
      "Mean Recall: 0.8618044338770522\n",
      "Mean F1: 0.8311050521157023\n",
      "Mean Specificity: 0.8386757970434882\n",
      "For Class Type 3\n",
      "Train Accuracy: 0.8578571428571429\n",
      "Test Accuracy: 0.8542857142857143\n",
      "Mean Precision: 0.808132183908046\n",
      "Mean Recall: 0.8685706117781591\n",
      "Mean F1: 0.8350851410370657\n",
      "Mean Specificity: 0.8461523034190377\n",
      "For Class Type 4\n",
      "Train Accuracy: 0.8578571428571429\n",
      "Test Accuracy: 0.8542857142857143\n",
      "Mean Precision: 0.8065827228327229\n",
      "Mean Recall: 0.862317218960127\n",
      "Mean F1: 0.8320984141035067\n",
      "Mean Specificity: 0.8451946079380809\n",
      "For Class Type 5\n",
      "Train Accuracy: 0.8589285714285715\n",
      "Test Accuracy: 0.85\n",
      "Mean Precision: 0.8094751336582988\n",
      "Mean Recall: 0.8500662850629398\n",
      "Mean F1: 0.8287683429907716\n",
      "Mean Specificity: 0.849715303837054\n",
      "Macro F1-score: 0.8325978421634754\n"
     ]
    }
   ],
   "source": [
    "# Preparing featureset and targets from dataset\n",
    "data = np.asarray(dataset)\n",
    "featureset = np.delete(data, 1024, axis=1)\n",
    "target = data.T[1024]\n",
    "\n",
    "x = featureset\n",
    "y = target\n",
    "\n",
    "train_accuracy = list()\n",
    "test_accuracy = list()\n",
    "Pscores = list()\n",
    "Rscores = list()\n",
    "Fscores = list()\n",
    "Sscores = list()\n",
    "\n",
    "TrainAcc = list()\n",
    "TestAcc = list()\n",
    "Prec = list()\n",
    "Recall = list()\n",
    "Spec = list()\n",
    "\n",
    "for obs_label in range(6):\n",
    "    for i in range(5):\n",
    "        x_train, x_test, y_train, y_test = au.cross_val_split(x, y, 5)[i]\n",
    "        model_gmm = pu.GMM()\n",
    "        model_gmm.fit(x_train)\n",
    "        y_test_hat = model_gmm.predict(x_test)\n",
    "        y_train_hat = model_gmm.predict(x_train)\n",
    "        train_accuracy.append(cmu.accuracy_calc(y_train, y_train_hat))\n",
    "        test_accuracy.append(cmu.accuracy_calc(y_test, y_test_hat))\n",
    "        Pscores.append(cmu.precision_calc(obs_label, y_test, y_test_hat))\n",
    "        Rscores.append(cmu.recall_calc(obs_label, y_test, y_test_hat))\n",
    "        Fscores.append(cmu.f1_calc(obs_label, y_test, y_test_hat))\n",
    "        Sscores.append(cmu.specificity_calc(obs_label,y_test, y_test_hat))\n",
    "    print(\"For Class Type\", obs_label)\n",
    "    print(\"Mean Train Accuracy:\", np.mean(train_accuracy))\n",
    "    print(\"Mean Test Accuracy:\", np.mean(test_accuracy))\n",
    "    print(\"Mean Precision:\", np.mean(Pscores))\n",
    "    print(\"Mean Recall:\", np.mean(Rscores))\n",
    "    print(\"Mean F1 score:\", np.mean(Fscores))\n",
    "    print(\"Mean Specificity:\", np.mean(Sscores))\n",
    "    TrainAcc.append(np.mean(train_accuracy))\n",
    "    TestAcc.append(np.mean(test_accuracy))\n",
    "    Prec.append(np.mean(Pscores))\n",
    "    Recall.append(np.mean(Rscores))\n",
    "    Spec.append(np.mean(Sscores))\n",
    "    \n",
    "Macro_prec = np.mean(Prec)\n",
    "Macro_recall = np.mean(Recall)\n",
    "Macro_F1 = 2*Macro_prec*Macro_recall/(Macro_prec + Macro_recall)\n",
    "print('Macro F1-score: %s' % Macro_F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 K-Nearest Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we classify the data sample into one of the target classes by evaluating which class has more data points in its neighbourhood (Euclidean Distance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Class Type 0\n",
      "Mean Train Accuracy: 0.8617857142857142\n",
      "Mean Test Accuracy: 0.832857142857143\n",
      "Mean Precision: 0.8279309968134412\n",
      "Mean Recall: 0.7497721184288348\n",
      "Mean F1 score: 0.7855974386523604\n",
      "Mean Specificity: 0.8902497985495568\n",
      "For Class Type 1\n",
      "Mean Train Accuracy: 0.8598214285714286\n",
      "Mean Test Accuracy: 0.8407142857142856\n",
      "Mean Precision: 0.8462172004700284\n",
      "Mean Recall: 0.7648084787301407\n",
      "Mean F1 score: 0.8014707184232959\n",
      "Mean Specificity: 0.8956741589280464\n",
      "For Class Type 2\n",
      "Mean Train Accuracy: 0.861904761904762\n",
      "Mean Test Accuracy: 0.8323809523809523\n",
      "Mean Precision: 0.8372225527495952\n",
      "Mean Recall: 0.7642764987954268\n",
      "Mean F1 score: 0.7965081400458401\n",
      "Mean Specificity: 0.8828788689145715\n",
      "For Class Type 3\n",
      "Mean Train Accuracy: 0.8620535714285713\n",
      "Mean Test Accuracy: 0.8325000000000001\n",
      "Mean Precision: 0.8289414455867273\n",
      "Mean Recall: 0.7720686463604793\n",
      "Mean F1 score: 0.796929080985145\n",
      "Mean Specificity: 0.8765978468710612\n",
      "For Class Type 4\n",
      "Mean Train Accuracy: 0.8642142857142858\n",
      "Mean Test Accuracy: 0.824857142857143\n",
      "Mean Precision: 0.8190017208629935\n",
      "Mean Recall: 0.7643461909442282\n",
      "Mean F1 score: 0.7885702656719935\n",
      "Mean Specificity: 0.8694898695358918\n",
      "For Class Type 5\n",
      "Mean Train Accuracy: 0.8653571428571428\n",
      "Mean Test Accuracy: 0.8207142857142858\n",
      "Mean Precision: 0.8163639863879534\n",
      "Mean Recall: 0.7603664731044458\n",
      "Mean F1 score: 0.7846470825024876\n",
      "Mean Specificity: 0.8664406074286185\n",
      "Macro F1-score: 0.7945467819291947\n"
     ]
    }
   ],
   "source": [
    "# Preparing featureset and targets from dataset\n",
    "data = np.asarray(dataset)\n",
    "featureset = np.delete(data, 1024, axis=1)\n",
    "target = data.T[1024]\n",
    "\n",
    "# testing the KNN algorithm with k=800\n",
    "x = featureset\n",
    "y = target\n",
    "\n",
    "train_accuracy = list()\n",
    "test_accuracy = list()\n",
    "Pscores = list()\n",
    "Rscores = list()\n",
    "Fscores = list()\n",
    "Sscores = list()\n",
    "\n",
    "TrainAcc = list()\n",
    "TestAcc = list()\n",
    "Prec = list()\n",
    "Recall = list()\n",
    "Spec = list()\n",
    "\n",
    "for obs_label in range(6):\n",
    "    for i in range(5):\n",
    "        x_train, x_test, y_train, y_test = au.cross_val_split(x, y, 5)[i]\n",
    "        model_knn = pu.KNN(k=10)\n",
    "        y_test_hat = model_knn.predict(x_test, x_train, y_train)\n",
    "        y_train_hat = model_knn.predict(x_train, x_train, y_train)\n",
    "        train_accuracy.append(cmu.accuracy_calc(y_train, y_train_hat))\n",
    "        test_accuracy.append(cmu.accuracy_calc(y_test, y_test_hat))\n",
    "        Pscores.append(cmu.precision_calc(obs_label, y_test, y_test_hat))\n",
    "        Rscores.append(cmu.recall_calc(obs_label, y_test, y_test_hat))\n",
    "        Fscores.append(cmu.f1_calc(obs_label, y_test, y_test_hat))\n",
    "        Sscores.append(cmu.specificity_calc(obs_label,y_test, y_test_hat))\n",
    "    print(\"For Class Type\", j)\n",
    "    print(\"Mean Train Accuracy:\", np.mean(train_accuracy))\n",
    "    print(\"Mean Test Accuracy:\", np.mean(test_accuracy))\n",
    "    print(\"Mean Precision:\", np.mean(Pscores))\n",
    "    print(\"Mean Recall:\", np.mean(Rscores))\n",
    "    print(\"Mean F1 score:\", np.mean(Fscores))\n",
    "    print(\"Mean Specificity:\", np.mean(Sscores))\n",
    "    TrainAcc.append(np.mean(train_accuracy))\n",
    "    TestAcc.append(np.mean(test_accuracy))\n",
    "    Prec.append(np.mean(Pscores))\n",
    "    Recall.append(np.mean(Rscores))\n",
    "    Spec.append(np.mean(Sscores))\n",
    "    \n",
    "Macro_prec = np.mean(Prec)\n",
    "Macro_recall = np.mean(Recall)\n",
    "Macro_F1 = 2*Macro_prec*Macro_recall/(Macro_prec + Macro_recall)\n",
    "print('Macro F1-score: %s' % Macro_F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Parzen Window density estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Class Type 0\n",
      "Mean Train Accuracy: 0.8578571428571429\n",
      "Mean Test Accuracy: 0.8542857142857143\n",
      "Mean Precision: 0.8353541251874075\n",
      "Mean Recall: 0.8359336004497294\n",
      "Mean F1 score: 0.8346152615305842\n",
      "Mean Specificity: 0.8702176255117433\n",
      "For Class Type 1\n",
      "Mean Train Accuracy: 0.8567857142857142\n",
      "Mean Test Accuracy: 0.8585714285714285\n",
      "Mean Precision: 0.8285446777693066\n",
      "Mean Recall: 0.842036083602801\n",
      "Mean F1 score: 0.8345629221569231\n",
      "Mean Specificity: 0.8703856204014567\n",
      "For Class Type 2\n",
      "Mean Train Accuracy: 0.8572619047619047\n",
      "Mean Test Accuracy: 0.8566666666666667\n",
      "Mean Precision: 0.8304936738841115\n",
      "Mean Recall: 0.8409525507127203\n",
      "Mean F1 score: 0.835075536641009\n",
      "Mean Specificity: 0.868522949419583\n",
      "For Class Type 3\n",
      "Mean Train Accuracy: 0.8563392857142856\n",
      "Mean Test Accuracy: 0.8603571428571429\n",
      "Mean Precision: 0.8379047981459173\n",
      "Mean Recall: 0.8434299464207207\n",
      "Mean F1 score: 0.8399151900352138\n",
      "Mean Specificity: 0.8729218713042066\n",
      "For Class Type 4\n",
      "Mean Train Accuracy: 0.8561428571428571\n",
      "Mean Test Accuracy: 0.8611428571428571\n",
      "Mean Precision: 0.8363287890108525\n",
      "Mean Recall: 0.8468134582197929\n",
      "Mean F1 score: 0.8408377708466687\n",
      "Mean Specificity: 0.871830415579615\n",
      "For Class Type 5\n",
      "Mean Train Accuracy: 0.8564880952380952\n",
      "Mean Test Accuracy: 0.8597619047619047\n",
      "Mean Precision: 0.8361425419871882\n",
      "Mean Recall: 0.8430323528284259\n",
      "Mean F1 score: 0.8389014888139699\n",
      "Mean Specificity: 0.8725446167865207\n",
      "Macro F1-score: 0.8380619098151944\n"
     ]
    }
   ],
   "source": [
    "# Preparing featureset and targets from dataset\n",
    "data = np.asarray(dataset)\n",
    "featureset = np.delete(data, 3, axis=1)\n",
    "target = data.T[3]\n",
    "\n",
    "# testing the PW algorithm with dist=1\n",
    "x = au.normalize(au.standardize(featureset))\n",
    "y = target\n",
    "\n",
    "train_accuracy = list()\n",
    "test_accuracy = list()\n",
    "Pscores = list()\n",
    "Rscores = list()\n",
    "Fscores = list()\n",
    "Sscores = list()\n",
    "\n",
    "TrainAcc = list()\n",
    "TestAcc = list()\n",
    "Prec = list()\n",
    "Recall = list()\n",
    "Spec = list()\n",
    "\n",
    "for obs_label in range(6):\n",
    "    for i in range(5):\n",
    "        x_train, x_test, y_train, y_test = au.cross_val_split(x, y, 5)[i]\n",
    "        model_pw = pu.PW(dist=1)\n",
    "        y_test_hat = model_pw.predict(x_test, x_train, y_train)\n",
    "        y_train_hat = model_pw.predict(x_train, x_train, y_train)\n",
    "        train_accuracy.append(cmu.accuracy_calc(y_train, y_train_hat))\n",
    "        test_accuracy.append(cmu.accuracy_calc(y_test, y_test_hat))\n",
    "        Pscores.append(cmu.precision_calc(obs_label, y_test, y_test_hat))\n",
    "        Rscores.append(cmu.recall_calc(obs_label, y_test, y_test_hat))\n",
    "        Fscores.append(cmu.f1_calc(obs_label, y_test, y_test_hat))\n",
    "        Sscores.append(cmu.specificity_calc(obs_label,y_test, y_test_hat))\n",
    "    print(\"For Class Type\", j)\n",
    "    print(\"Mean Train Accuracy:\", np.mean(train_accuracy))\n",
    "    print(\"Mean Test Accuracy:\", np.mean(test_accuracy))\n",
    "    print(\"Mean Precision:\", np.mean(Pscores))\n",
    "    print(\"Mean Recall:\", np.mean(Rscores))\n",
    "    print(\"Mean F1 score:\", np.mean(Fscores))\n",
    "    print(\"Mean Specificity:\", np.mean(Sscores))\n",
    "    TrainAcc.append(np.mean(train_accuracy))\n",
    "    TestAcc.append(np.mean(test_accuracy))\n",
    "    Prec.append(np.mean(Pscores))\n",
    "    Recall.append(np.mean(Rscores))\n",
    "    Spec.append(np.mean(Sscores))\n",
    "    \n",
    "Macro_prec = np.mean(Prec)\n",
    "Macro_recall = np.mean(Recall)\n",
    "Macro_F1 = 2*Macro_prec*Macro_recall/(Macro_prec + Macro_recall)\n",
    "print('Macro F1-score: %s' % Macro_F1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
